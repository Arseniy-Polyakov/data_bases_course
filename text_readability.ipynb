{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC3Jx4R5FAhwB0J4cDmt4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arseniy-Polyakov/data_bases_course/blob/main/text_readability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данный ноутбук посвящен расчету количественных метрик оценивания сложности текстов на разных уровней для сбора данных для базы"
      ],
      "metadata": {
        "id": "tcQGXQHjfce_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве сбора данных будет использовать платформу Kaggle, в частности датасет размеченных английских текстов по уровням CEFR и считать для них метрики на каждом лингвистическом уровне (фонологический, грамматический, лексический + количественные метрики отображающие диапазоны сложности текстов, например, FRE (Коэффициент Флеша), SMOG, LIX и т.д.)"
      ],
      "metadata": {
        "id": "yIbUnQmTf_pw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем библиотеки и модули для сбора, обработки и анализа текстовых данных"
      ],
      "metadata": {
        "id": "av_g-HHBgePc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz1xT6TvfYht"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем стоп-слова для аннглийского языка и словарь меток для частеречной разметки"
      ],
      "metadata": {
        "id": "r-4iPkhG2BO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"universal_tagset\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNs6vUret2Nt",
        "outputId": "ad761fa4-2482-466d-f42d-5e1f414cada7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем переменную со стоп-словами"
      ],
      "metadata": {
        "id": "TqFg41sZ2KEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "3K1E1HZhw9Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет"
      ],
      "metadata": {
        "id": "HAKNVcKZ2NBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"amontgomerie/cefr-levelled-english-texts\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWOC8yeNgmLv",
        "outputId": "89e8b7f9-fed8-4b13-a742-9773a28ff775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/cefr-levelled-english-texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/cefr-levelled-english-texts/cefr_leveled_texts.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W-dOWtvagqz_",
        "outputId": "d1155df4-718e-44cb-a998-e9a83202455d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text label\n",
              "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
              "1  ﻿It was not so much how hard people found the ...    B2\n",
              "2  Keith recently came back from a trip to Chicag...    B2\n",
              "3  The Griffith Observatory is a planetarium, and...    B2\n",
              "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04001aa1-8336-46da-89c8-d721f353e885\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>﻿It was not so much how hard people found the ...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Keith recently came back from a trip to Chicag...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04001aa1-8336-46da-89c8-d721f353e885')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04001aa1-8336-46da-89c8-d721f353e885 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04001aa1-8336-46da-89c8-d721f353e885');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-405e0369-7594-4392-baf7-b394fc779583\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-405e0369-7594-4392-baf7-b394fc779583')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-405e0369-7594-4392-baf7-b394fc779583 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1494,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1493,\n        \"samples\": [\n          \"Clay Cockrell is sitting in his office at Columbus Circle, across the street from 1 Central Park West, which houses Trump International Hotel and Tower. In front of the tower is Central Park, where Cockrell holds his popular walk and talk therapy sessions. \\nCockrell, a former Wall Street worker turned therapist, spends large parts of his days walking through Central Park or the Battery Park in downtown Manhattan near Wall Street, as a confidant and counsellor to some of New York\\u2019s wealthiest people. \\n\\u201cI shifted towards it naturally,\\u201d he said of his becoming an expert in wealth therapy. \\u201cMany of the extremely wealthy \\u2013 the 1% of the 1% \\u2013 feel that their problems are really not problems. But they are. A lot of therapists do not give enough weight to their issues.\\u201d \\nSo, what issues are America\\u2019s 1% struggling with? \\u201cThere is guilt over being rich in the first place,\\u201d he said. \\u201cThere is the feeling that they have to hide the fact that they are rich. And, then, there is the isolation \\u2013 being in the 1%, it turns out, can be lonely.\\u201d It seems F Scott Fitzgerald was right: the very rich \\u201care different from you and me\\u201d. \\nCounsellors argue things have become worse since the financial crisis and the debate over income inequality that has been spurred on by movements like Occupy Wall Street and the Fight for $15 fair wage campaign. \\n\\u201cThe Occupy Wall Street movement was a good one and had some important things to say about income inequality but it singled out the 1% and painted them globally as something negative,\\u201d said Jamie Traeger-Muney, a wealth psychologist and founder of the Wealth Legacy Group. The media, she said, is partly to blame for making the rich \\u201cfeel like they need to hide or feel ashamed\\u201d. \\n\\u201cSometimes, I am shocked by things that people say. You would never refer to another group of people in the way that it seems perfectly normal to refer to wealth holders.\\u201d \\n\\u201cIt\\u2019s really isolating to have a lot of money. People\\u2019s reactions to you can be scary,\\u201d said Barbara Nusbaum, an expert in money psychology. \\u201cWe are all taught not to talk about money. It\\u2019s not polite to talk about money. Ironically, it\\u2019s harder to talk about having money than it is to talk about not having money. It\\u2019s much more socially acceptable to say 'I am broke. Things are hard.' You can\\u2019t say 'I have a ton of money.' You have to keep a lot of your life private.\\u201d \\nAs a result, Cockrell points out, the rich tend to hang out with other rich Americans, not out of snobbery but in order to be around those who understand them and their problems. \\nThe growing gap between the rich and poor is a global phenomenon. According to Oxfam, the richest 1% have seen their share of global wealth increase from 44% in 2009 to 48% in 2014 and are on track to own more than the other 99% by 2016. \\nIn the US, over the last three decades, the wealth owned by the top 0.1% households increased from 7% to 22% even as the wealth of the bottom 90% of households declined. \\nThe number of extremely wealthy people has also been climbing. According to research from Spectrem Group, in 2014, the number of US households with $1m or more in assets \\u2013 excluding the value of their primary home \\u2013 increased by 500,000 to 10.1m. In 2007, that number was 9.2m. Households worth $5m or more reached 1.3m and 142,000 households are now worth $25m or more. \\nSince the 2008 financial crisis, the income gap has expanded and the situation \\u201chas gotten worse for the wealthy\\u201d, Cockrell said. The main reason? Not knowing if your friends are friends with you or your money. \\n\\u201cSomeone else who is also a billionaire \\u2013 they don\\u2019t want anything from you. Never being able to trust your friendships with people of different means, I think that is difficult,\\u201d said Cockrell. \\u201cAs the gap has widened, the rich have become more and more isolated.\\u201d \\nThese are real fears faced by the richest of the rich. In 2007, the Gates Foundation teamed up with Boston College\\u2019s Center on Wealth and Philanthropy to document what it felt like to be in America\\u2019s 1%. For the next four years, researchers surveyed 165 of America\\u2019s richest households \\u2013 120 of those households have at least $25m in assets. The average net worth of those surveyed was $78m. The resulting study, The Joys and Dilemmas of Wealth, was 500 pages long and seemed to prove the old adage that money can\\u2019t buy happiness. \\n\\u201cWealth can be a barrier to connecting with other people,\\u201d confessed a spouse of a tech entrepreneur who made about $80m. Some Americans have taken to keeping their wealth secret. \\u201cWe talk about it as stealth wealth. There are a lot of people that are hiding their wealth because they are concerned about negative judgment,\\u201d said Traeger-Muney. If wealthy Americans talk about the unique challenges that come with their wealth, people often dismiss their experience. \\n\\u201cPeople say 'Oh, poor you.' There is not a lot of sympathy there,\\u201d she said. \\u201cWealth is still one of our last taboos.\\u201d \\nSpeaking in his soft, soothing voice that makes you want to spill all your worries, Cockrell said that a common mistake that many of his wealthy clients make is letting their money define them. \\n\\u201cI don\\u2019t think it\\u2019s healthy to discount your problems. If you are part of the 1%, you still have problems and they are legitimate to you. Even when you say, 'I don\\u2019t have to struggle for money', there are other parts of your life. Money is not the only thing that defines you,\\u201d he said. \\u201cYour problems are legitimate.\\u201d\\n\",\n          \"If you think of the jobs robots could never do, you would probably put doctors and teachers at the top of the list. It's easy to imagine robot cleaners and factory workers, but some jobs need human connection and creativity. But are we underestimating what robots can do? In some cases, they already perform better than doctors at diagnosing illness. Also, some patients might feel more comfortable sharing personal information with a machine than a person. Could there be a place for robots in education after all?\\nBritish education expert Anthony Seldon thinks so. And he even has a date for the robot takeover of the classroom: 2027. He predicts robots will do the main job of transferring information and teachers will be like assistants. Intelligent robots will read students' faces, movements and maybe even brain signals. Then they will adapt the information to each student. It's not a popular opinion and it's unlikely robots will ever have empathy and the ability to really connect with humans like another human can.\\nOne thing is certain, though. A robot teacher is better than no teacher at all. In some parts of the world, there aren't enough teachers and 9\\u201316 per cent of children under the age of 14 don't go to school. That problem could be partly solved by robots because they can teach anywhere and won't get stressed, or tired, or move somewhere for an easier, higher-paid job.\\nThose negative aspects of teaching are something everyone agrees on. Teachers all over the world are leaving because it is a difficult job and they feel overworked. Perhaps the question is not 'Will robots replace teachers?' but 'How can robots help teachers?' Office workers can use software to do things like organise and answer emails, arrange meetings and update calendars. Teachers waste a lot of time doing non-teaching work, including more than 11 hours a week marking homework. If robots could cut the time teachers spend marking homework and writing reports, teachers would have more time and energy for the parts of the job humans do best.\",\n          \"In the philosophy of religion, creation is the action by which God brings an object into existence, while conservation is the action by which God maintains the existence of an object over time. The major monotheisms unambiguously affirm that God both created the world and conserves it. It is less clear, however, whether creation and conservation are to be conceived as distinct kinds of actions. The question has its roots in medieval and early modern characterizations of divine action, and it has received renewed attention in recent decades.\\nOn the predominant traditional view, conservation is continuous creation. Adherents of this view typically say with Francisco Su\\u00e1rez that God\\u2019s creation and conservation of things are \\u201conly conceptually distinct\\u201d (Su\\u00e1rez 1597, 120). Jonathan Edwards, for example, says, \\u201cGod\\u2019s upholding created substance, or causing its existence in each successive moment, is altogether equivalent to an immediate production out of nothing, at each moment\\u2026. So that this effect differs not at all from the first creation, but only circumstantially\\u2026\\u201d (Edwards 1758, 402; emphasis in the original). In other words, there is no real difference between the act of creation and the act of conservation, though different words may be used for them. Descartes, Malebranche, Leibniz, and Berkeley all express similar views. More recently, Philip Quinn likewise treats both God\\u2019s creating and God\\u2019s conserving as species of bringing about a thing\\u2019s existence. We call the act \\u2018creation\\u2019 if it occurs at the first time at which the creature exists, and we call it \\u2018conservation\\u2019 if it occurs at a later time, but the action is the same (e.g., Quinn 1988, 54).\\nThe alternative to this view is that the act of conserving beings that already exist differs from calling beings into existence from nothing. Some argue that each persisting creature plays a causal role in its ongoing existence, so that God is not the sole agent as in an ex nihilo creation. Some also argue that conservation must be an ongoing act, whereas creation occurs at an instant.\\nA large part of what is at stake in the debate is the relationship between divine action and creaturely action. Continuous creation theorists may reject a distinction between creation and conservation as an attempt to attribute a divine prerogative to created things. On the other hand, those who endorse a distinction may regard continuous creation theory as (to borrow a phrase) \\u201cone of those high-minded philosophical depreciations of God\\u2019s works that come disguised as compliments to God\\u2019s person\\u201d (van Inwagen 1988, 46 n4). The debate also raises a number of interesting questions about causation, time, and their relations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"B2\",\n          \"A2\",\n          \"C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Импортируем в csv формате файл с текстами и их id"
      ],
      "metadata": {
        "id": "jYAoyoBGC0BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [str(random.randint(1000000, 9999999)) for i in range(len(df))]\n",
        "df[\"text_id\"] = ids\n",
        "df_general = df[[\"text\", \"text_id\"]]\n",
        "df_general.to_csv(\"/content/csv/general.csv\")\n",
        "\n",
        "df_general_no_texts = df[\"text_id\"]\n",
        "df_general_no_texts.to_csv(\"/content/csv/general_no_texts.csv\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qFqR8bLljaU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df[\"text\"].tolist()"
      ],
      "metadata": {
        "id": "N-Y7-Hp7CsbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пишем функцию препроцессинга текста (удаление знаков препинания, цифр, символов других алфавитов)"
      ],
      "metadata": {
        "id": "qpifZPB32QR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text: str) -> str:\n",
        "  texts_splitted = \"\".join(re.split(\"\\n\", text))\n",
        "  text_cleaned = re.sub(r\"[^a-z'\\-\\s]\", \"\", texts_splitted.lower())\n",
        "  return text_cleaned"
      ],
      "metadata": {
        "id": "0VSscT_7ji4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_preprocessed = [preprocessing(text) for text in texts]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tDs5l6agjylO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Фонологический уровень (односложные, двусложные, трехсложные, четырехсложные слова). Импортируем финальный csv файл для базы данных"
      ],
      "metadata": {
        "id": "vFQyAeOlsndw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def syllables_counting(word):\n",
        "  vowels = [\"a\", \"o\", \"e\", \"y\", \"u\", \"i\"]\n",
        "  digrafs_and_trigrafs = [\"ai\", \"ay\", \"ea\", \"ee\", \"ei\", \"ey\", \"oa\", \"oe\", \"oo\", \"ou\",\n",
        "                      \"ua\", \"ue\", \"ui\", \"uy\", \"eau\", \"aye\", \"iou\"]\n",
        "  vowels_count = len([symbol for symbol in word if symbol in vowels])\n",
        "  digrafs_and_trigrafs_count = len([item for item in digrafs_and_trigrafs if item in word])\n",
        "  limitations = [\"the\", \"he\", \"she\", \"me\", \"we\", \"cafe\", \"apostrophe\", \"cliche\"]\n",
        "  final_count = vowels_count - digrafs_and_trigrafs_count\n",
        "  if word.endswith(\"e\") and word not in limitations:\n",
        "    final_count -= 1\n",
        "  if word.startswith(\"y\"):\n",
        "    final_count -= 1\n",
        "  return final_count"
      ],
      "metadata": {
        "id": "If1PVoWgq1c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def phonological_level(text: str) -> dict:\n",
        "  one_syllable, two_syllables, three_syllables, four_syllables, five_and_more_syllables = 0, 0, 0, 0, 0\n",
        "  for word in text.split():\n",
        "    if syllables_counting(word) == 1:\n",
        "      one_syllable +=1\n",
        "    elif syllables_counting(word) == 2:\n",
        "      two_syllables += 1\n",
        "    elif syllables_counting(word) == 3:\n",
        "      three_syllables += 1\n",
        "    elif syllables_counting(word) == 4:\n",
        "      four_syllables += 1\n",
        "    else:\n",
        "      five_and_more_syllables += 1\n",
        "\n",
        "  phonological_level_df = {\n",
        "      \"one_syllable_words\": one_syllable,\n",
        "      \"two_syllable_words\": two_syllables,\n",
        "      \"three_syllables_words\": three_syllables,\n",
        "      \"four_syllables_words\": four_syllables,\n",
        "      \"five_and_more_syllables_words\": five_and_more_syllables\n",
        "  }\n",
        "  return phonological_level_df"
      ],
      "metadata": {
        "id": "hzVAT2ODjG65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_syllable_dataset = []\n",
        "two_syllables_dataset = []\n",
        "three_syllables_dataset = []\n",
        "four_syllables_dataset = []\n",
        "five_and_more_syllables_dataset = []\n",
        "\n",
        "for text in tqdm(texts_preprocessed):\n",
        "  phonological_level_stat = phonological_level(text)\n",
        "  one_syllable_dataset.append(phonological_level_stat[\"one_syllable_words\"])\n",
        "  two_syllables_dataset.append(phonological_level_stat[\"two_syllable_words\"])\n",
        "  three_syllables_dataset.append(phonological_level_stat[\"three_syllables_words\"])\n",
        "  four_syllables_dataset.append(phonological_level_stat[\"four_syllables_words\"])\n",
        "  five_and_more_syllables_dataset.append(phonological_level_stat[\"five_and_more_syllables_words\"])\n",
        "\n",
        "df_phonological = pd.DataFrame(ids,\n",
        "                               index=[i for i in range(len(texts_preprocessed))],\n",
        "                               columns=[\"text_id\"])\n",
        "\n",
        "df_phonological[\"one_syllable_words\"] = one_syllable_dataset\n",
        "df_phonological[\"two_syllables_words\"] = two_syllables_dataset\n",
        "df_phonological[\"three_syllables_words\"] = three_syllables_dataset\n",
        "df_phonological[\"four_syllables_words\"] = four_syllables_dataset\n",
        "df_phonological[\"five_and_more_syllables_words\"] = five_and_more_syllables_dataset\n",
        "\n",
        "df_phonological.head()\n",
        "df_phonological.to_csv(\"/content/csv/phonological_level.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgaD9ekV5v3p",
        "outputId": "48a34f92-3ccb-46ee-a491-c9e2e1a45e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1494/1494 [00:02<00:00, 520.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "II. Грамматический уровень (частеречная разметка, номинативность и дескриптивность). Импортируем финальный csv файл для базы данных"
      ],
      "metadata": {
        "id": "ZSmafhq5swVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grammatical_level(text: list):\n",
        "  pos_tags = nltk.tag.pos_tag(text, tagset=\"universal\")\n",
        "\n",
        "  pos_count = {\n",
        "      \"nouns\": 0,\n",
        "      \"adjectives\": 0,\n",
        "      \"verbs\": 0,\n",
        "      \"adverbs\": 0,\n",
        "      \"pronouns\": 0,\n",
        "      \"numerals\": 0\n",
        "  }\n",
        "\n",
        "  for tag in pos_tags:\n",
        "    if tag[1] == \"NOUN\":\n",
        "      pos_count[\"nouns\"] += 1\n",
        "    elif tag[1] == \"ADJ\":\n",
        "      pos_count[\"adjectives\"] += 1\n",
        "    elif tag[1] == \"VERB\":\n",
        "      pos_count[\"verbs\"] += 1\n",
        "    elif tag[1] == \"ADV\":\n",
        "      pos_count[\"adverbs\"] += 1\n",
        "    elif tag[1] == \"PRON\":\n",
        "      pos_count[\"pronouns\"] += 1\n",
        "    elif tag[1] == \"NUM\":\n",
        "      pos_count[\"numerals\"] += 1\n",
        "\n",
        "  text_without_stopwords = [token for token in text if token not in stop_words]\n",
        "\n",
        "  nominativity = round(pos_count[\"nouns\"] / len(text_without_stopwords), 2)\n",
        "  descriptivity = round(pos_count[\"adjectives\"] / len(text_without_stopwords), 2)\n",
        "\n",
        "  grammatical_level_stat = {\n",
        "      \"nominativity\": nominativity,\n",
        "      \"descriptivity\": descriptivity,\n",
        "      \"nouns\": pos_count[\"nouns\"],\n",
        "      \"adjectives\": pos_count[\"adjectives\"],\n",
        "      \"verbs\": pos_count[\"verbs\"],\n",
        "      \"adverbs\": pos_count[\"adverbs\"],\n",
        "      \"pronouns\": pos_count[\"pronouns\"],\n",
        "      \"numerals\": pos_count[\"numerals\"]\n",
        "  }\n",
        "  return grammatical_level_stat"
      ],
      "metadata": {
        "id": "nfQNZ0pRs15v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nominativity_dataset = []\n",
        "descriptivity_dataset = []\n",
        "nouns_dataset = []\n",
        "adjectives_dataset = []\n",
        "verbs_dataset = []\n",
        "adverbs_dataset = []\n",
        "pronouns_dataset = []\n",
        "numerals_dataset = []\n",
        "\n",
        "for text in tqdm(texts_preprocessed):\n",
        "  grammatical_dataset = grammatical_level(text.split())\n",
        "  nominativity_dataset.append(grammatical_dataset[\"nominativity\"])\n",
        "  descriptivity_dataset.append(grammatical_dataset[\"descriptivity\"])\n",
        "  nouns_dataset.append(grammatical_dataset[\"nouns\"])\n",
        "  adjectives_dataset.append(grammatical_dataset[\"adjectives\"])\n",
        "  verbs_dataset.append(grammatical_dataset[\"verbs\"])\n",
        "  adverbs_dataset.append(grammatical_dataset[\"adverbs\"])\n",
        "  pronouns_dataset.append(grammatical_dataset[\"pronouns\"])\n",
        "  numerals_dataset.append(grammatical_dataset[\"numerals\"])\n",
        "\n",
        "df_grammatical = pd.DataFrame(ids,\n",
        "                              index=[i for i in range(len(texts_preprocessed))],\n",
        "                              columns=[\"text_id\"])\n",
        "\n",
        "df_grammatical[\"nominativity\"] = nominativity_dataset\n",
        "df_grammatical[\"descriptivity\"] = descriptivity_dataset\n",
        "df_grammatical[\"nouns\"] = nouns_dataset\n",
        "df_grammatical[\"adjectives\"] = adjectives_dataset\n",
        "df_grammatical[\"verbs\"] = verbs_dataset\n",
        "df_grammatical[\"adverbs\"] = adverbs_dataset\n",
        "df_grammatical[\"pronouns\"] = pronouns_dataset\n",
        "df_grammatical[\"numerals\"] = numerals_dataset\n",
        "\n",
        "df_grammatical.head()\n",
        "df_grammatical.to_csv(\"/content/csv/grammatical_level.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBxmH-OK8HcL",
        "outputId": "3280e3c9-97c3-4bd1-fa24-eb7b75cdaeb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1494/1494 [00:24<00:00, 60.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "III. Лексический уровень (TTR, RTTR, CTTR). Импортируем финальный csv файл для базы данных"
      ],
      "metadata": {
        "id": "Mkbc73BPzDdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_level(text: list) -> dict:\n",
        "  unique_words = set(text)\n",
        "  ttr = round(len(unique_words) / len(text), 2)\n",
        "  rttr = round(len(unique_words) / (len(text)**0.5), 2)\n",
        "  cttr = round(len(unique_words) / (len(text)*2)**0.5, 2)\n",
        "  lexical_level = {\n",
        "      \"ttr\": ttr,\n",
        "      \"rttr\": rttr,\n",
        "      \"cttr\": cttr\n",
        "  }\n",
        "  return lexical_level"
      ],
      "metadata": {
        "id": "i4ly3EC0zHa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttr_dataset = []\n",
        "rttr_dataset = []\n",
        "cttr_dataset = []\n",
        "cefr_level_dataset = df[\"label\"].tolist()\n",
        "for text in tqdm(texts_preprocessed):\n",
        "  lexical_dataset = lexical_level(text.split())\n",
        "  ttr_dataset.append(lexical_dataset[\"ttr\"])\n",
        "  rttr_dataset.append(lexical_dataset[\"rttr\"])\n",
        "  cttr_dataset.append(lexical_dataset[\"cttr\"])\n",
        "\n",
        "df_lexical = pd.DataFrame(ids,\n",
        "                          index=[i for i in range(len(texts_preprocessed))],\n",
        "                          columns=[\"text_id\"])\n",
        "\n",
        "df_lexical[\"ttr\"] = ttr_dataset\n",
        "df_lexical[\"rttr\"] = rttr_dataset\n",
        "df_lexical[\"cttr\"] = cttr_dataset\n",
        "df_lexical[\"cefr_level\"] = cefr_level_dataset\n",
        "df_lexical.head()\n",
        "df_lexical.to_csv(\"/content/csv/lexical_level.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn9mdlG_-YDo",
        "outputId": "11e1b880-5199-4ec4-ae66-7b12528d3642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1494/1494 [00:00<00:00, 17680.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IV. Статистические метрики (FKRI, gunning fox, SMOG, ARI, spache, dall, powers sumnel, coleman liau, lix, rix). Импортируем финальный csv файл для базы данных"
      ],
      "metadata": {
        "id": "u7rL0Zqd0UJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flesch_kincaid_readability_index(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  syllables = sum([syllables_counting(word) for word in words])\n",
        "  FKGL = round(0.39*(len(words)/len(sentences)) + (11.8*syllables/len(words)) - 15.59, 2)\n",
        "  return FKGL"
      ],
      "metadata": {
        "id": "C_4d2yYQlwgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gunning_fog_index(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  complex_words = [word for word in words if syllables_counting(word) >= 3]\n",
        "  FOG = round((0.4*((len(words)/len(sentences))) + (100*(len(complex_words)/len(words)))), 2)\n",
        "  return FOG"
      ],
      "metadata": {
        "id": "NHuOgsTvl6Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_measure_of_gobbledygook(text: str) -> float:\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  complex_words = [word for word in words if syllables_counting(word) >= 3]\n",
        "  root = round(len(complex_words)**0.5, 0)\n",
        "  part = root % 10\n",
        "  if part < 5:\n",
        "    rounded_ten = root - part\n",
        "  else:\n",
        "    rounded_ten = root + part\n",
        "  SMOG = 3 + rounded_ten\n",
        "  return SMOG"
      ],
      "metadata": {
        "id": "bj5gV4U2l_OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def automated_readability_index(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  characters = re.sub(r\"[^A-Za-z]\", \"\", text)\n",
        "  ARI = round(4.71*(len(characters)/len(words)) + 0.5*(len(words)/len(sentences)) - 21.43, 2)\n",
        "  return ARI"
      ],
      "metadata": {
        "id": "REyXiDCkmLQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spache_formula(text: str) -> float:\n",
        "  with open(\"/content/spache_words.txt\", \"rt\", encoding=\"utf-8\") as file:\n",
        "    spache_words = file.read().split()\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  average_sentence_length = round(len(words) / len(sentences), 2)\n",
        "  unique_unfamiliar_words = [word for word in words if word not in spache_words]\n",
        "  percent_unfamiliar_words = (len(unique_unfamiliar_words) * 100) / len(words)\n",
        "  spache = round((0.121*average_sentence_length) + (0.082*percent_unfamiliar_words) + 0.659, 2)\n",
        "  return spache"
      ],
      "metadata": {
        "id": "NwFFVZyDmQGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dale_chall(text: str) -> float:\n",
        "  with open(\"/content/dale_chall.txt\", \"rt\", encoding=\"utf-8\") as file:\n",
        "    dale_chall = file.read().split()\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  complex_words = [word for word in words if word not in dale_chall]\n",
        "  dale_chall = round(0.1579*(100*(len(complex_words)/len(words)) + 0.0496*(len(words)/len(sentences))), 2)\n",
        "  return dale_chall"
      ],
      "metadata": {
        "id": "D_Ul9RFemk0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def powers_sumner_kearl(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  average_sentence_length = round(len(words)/len(sentences), 2)\n",
        "  syllables = sum([syllables_counting(word) for word in words])\n",
        "  powers_sumner_kearl = round((0.0778*average_sentence_length) + (0.0455*syllables) + 2.7971, 2)\n",
        "  return powers_sumner_kearl"
      ],
      "metadata": {
        "id": "dVniAC-smsuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coleman_liau_index(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  letters = [len(word) for word in words]\n",
        "  average_letters = sum(letters) / (len(words) / 100)\n",
        "  average_sentences = len(sentences) / (len(words) / 100)\n",
        "  coleman_index = round((0.0588*average_letters) - (0.296*average_sentences) - 15.8, 2)\n",
        "  return coleman_index"
      ],
      "metadata": {
        "id": "ea2P87_VmybN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lix(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  long_words = [word for word in words if len(word) >= 7]\n",
        "  words_per_sentence = [len(nltk.word_tokenize(sentence)) for sentence in sentences]\n",
        "  average_number_words_per_sentence = sum(words_per_sentence) / len(words_per_sentence)\n",
        "  lix = round((len(long_words) * 100 / len(words)) + average_number_words_per_sentence, 2)\n",
        "  return lix"
      ],
      "metadata": {
        "id": "GvM4JYZ7m3tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rix(text: str) -> float:\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  long_words = [word for word in words if len(word) >= 7]\n",
        "  rix = round(len(long_words) / len(sentences), 2)\n",
        "  return rix"
      ],
      "metadata": {
        "id": "XHlq4VfKnDSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistical_level(text: str) -> dict:\n",
        "  statistical_level = {\n",
        "      \"fre\": flesch_kincaid_readability_index(text),\n",
        "      \"gunning_fog_index\": gunning_fog_index(text),\n",
        "      \"smog\": simple_measure_of_gobbledygook(text),\n",
        "      \"ari\": automated_readability_index(text),\n",
        "      \"spache_formula\": spache_formula(text),\n",
        "      \"dale_chall\": dale_chall(text),\n",
        "      \"powers_sumner_kearl\": powers_sumner_kearl(text),\n",
        "      \"coleman_liau_index\": coleman_liau_index(text),\n",
        "      \"lix\": lix(text),\n",
        "      \"rix\": rix(text)\n",
        "  }\n",
        "  return statistical_level"
      ],
      "metadata": {
        "id": "FLmRRNXS1Xbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flesch_kincaid_readability_index_dataset = []\n",
        "gunning_fog_index_dataset = []\n",
        "simple_measure_of_gobbledygook_dataset = []\n",
        "automated_readability_index_dataset = []\n",
        "spache_formula_dataset = []\n",
        "dale_chall_dataset = []\n",
        "powers_sumner_kearl_dataset = []\n",
        "coleman_liau_index_dataset = []\n",
        "lix_dataset = []\n",
        "rix_dataset = []\n",
        "\n",
        "for text in tqdm(texts_preprocessed):\n",
        "  statistical_level_dataset = statistical_level(text)\n",
        "  flesch_kincaid_readability_index_dataset.append(statistical_level_dataset[\"fre\"])\n",
        "  gunning_fog_index_dataset.append(statistical_level_dataset[\"gunning_fog_index\"])\n",
        "  simple_measure_of_gobbledygook_dataset.append(statistical_level_dataset[\"smog\"])\n",
        "  automated_readability_index_dataset.append(statistical_level_dataset[\"ari\"])\n",
        "  spache_formula_dataset.append(statistical_level_dataset[\"spache_formula\"])\n",
        "  dale_chall_dataset.append(statistical_level_dataset[\"dale_chall\"])\n",
        "  powers_sumner_kearl_dataset.append(statistical_level_dataset[\"powers_sumner_kearl\"])\n",
        "  coleman_liau_index_dataset.append(statistical_level_dataset[\"coleman_liau_index\"])\n",
        "  lix_dataset.append(statistical_level_dataset[\"lix\"])\n",
        "  rix_dataset.append(statistical_level_dataset[\"rix\"])\n",
        "\n",
        "df_statistical = pd.DataFrame(ids,\n",
        "                              index=[i for i in range(len(texts_preprocessed))],\n",
        "                              columns=[\"text_id\"])\n",
        "\n",
        "df_statistical[\"fre\"] = flesch_kincaid_readability_index_dataset\n",
        "df_statistical[\"gunning_fog_index\"] = gunning_fog_index_dataset\n",
        "df_statistical[\"smog\"] = simple_measure_of_gobbledygook_dataset\n",
        "df_statistical[\"ari\"] = automated_readability_index_dataset\n",
        "df_statistical[\"spache_formula\"] = spache_formula_dataset\n",
        "df_statistical[\"dale_chall\"] = dale_chall_dataset\n",
        "df_statistical[\"powers_sumner_kearl\"] = powers_sumner_kearl_dataset\n",
        "df_statistical[\"coleman_liau_index\"] = coleman_liau_index_dataset\n",
        "df_statistical[\"lix\"] = coleman_liau_index_dataset\n",
        "df_statistical[\"rix\"] = rix_dataset\n",
        "\n",
        "df_statistical.head()\n",
        "df_statistical.to_csv(\"/content/csv/statistical_level.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGnr0xti21HR",
        "outputId": "4f0bca75-d003-4ba7-9a15-c5e5c1cabbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1494/1494 [00:58<00:00, 25.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Источники:\n",
        "1. Поляков, А. М. Количественные критерии оценки сложности текста для методических целей / А. М. Поляков // Наука в мегаполисе Science in a Megapolis. – 2024. – № 3(59). – EDN FOFGKS. [Ссылка](https://mgpu-media.ru/issues/issue-59/literaturovedenie-i-yazykoznanie/kolichestvennye-kriterii-otsenki-slozhnosti-teksta-dlya-metodicheskikh-tselej.html?ysclid=mcaxhunvbp187574973)\n",
        "2. Поляков, А. М. Обработка текста на лексическом и семантическом уровнях для методических целей / А. М. Поляков // Фундаментальная и прикладная лингвистика : Материалы I Межвузовской студенческой конференции, Москва, 30 октября 2023 года. – Москва: Издательство МГТУ им. Н.Э. Баумана, 2024. – С. 54-56. – EDN SYCUTX.\n",
        "3. https://github.com/Arseniy-Polyakov/English-Texts-Complexity-Evaluation/tree/main\n",
        "4. https://github.com/Arseniy-Polyakov/LLM_vs_script_readability_formulas\n"
      ],
      "metadata": {
        "id": "27slSvwzoWjm"
      }
    }
  ]
}